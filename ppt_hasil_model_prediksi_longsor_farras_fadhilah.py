# -*- coding: utf-8 -*-
"""PPT_HASIL_Model Prediksi Longsor_Farras Fadhilah.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eGw1ouKrK8npdwi3VLYAd5khot6CWdJY

#**~ PREDIKSI LONGSOR DENGAN INTEGRASI DATA LINGKUNGAN & MACHINE LEARNING PIPELINE ~**
By : Farras Fadhilah (2106723565)

##**1. PENDAHULUAN**

Berdasarkan hasil review dan modifikasi pada contoh scipt, saya menggunakan data spasial untuk melakukan prediksi tanah longsor menggunakan integrasi data lingkungan dan *machine learning pipeline*. Berikut adalah tahapannya:

##**2. PERSIAPAN**

###`Library Installation`
"""

pip install geopandas

pip install pyspatialml

"""Setelah instalasi, masuk ke file berikut:
1. "/usr/local/lib/python3.10/dist-packages/pyspatialml/raster.py". Open the files by double click, Line 2563 of raster.py need be edited. `From`: pixel_indices = np.zeros(0, dtype=np.int) -> `To`: pixel_indices = np.zeros(0, dtype=np.int_) -> to save the change **Ctrl+s**


2. "/usr/local/lib/python3.10/dist-packages/pyspatialml/transformers.py". Open the files by double click, Line 213 of transformers.py need be edited. `From`: mask = np.zeros(neighbor_dist.shape, dtype=np.bool) -> `To`: mask = np.zeros(neighbor_dist.shape, dtype=np.bool_) -> to save the change **Ctrl+s**

### `Import`
"""

from copy import deepcopy
from tempfile import NamedTemporaryFile
from pyspatialml import Raster
from pyspatialml.preprocessing import xy_coordinates, distance_to_corners
import pyspatialml.datasets.meuse as ms
from pyspatialml.raster import reproject
import pyspatialml as psl

import numpy as np
import geopandas as gpd
from geopandas import GeoSeries, GeoDataFrame
from shapely.geometry import Point

import matplotlib as mpl
import matplotlib.pyplot as plt
from matplotlib import cm
from matplotlib.colors import ListedColormap

import os
import time
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.model_selection import cross_validate, KFold
from sklearn.model_selection import GridSearchCV

"""### `Setting Environment`"""

from google.colab import drive
drive.mount('/content/drive')

os.chdir("drive/MyDrive/KokusB/06_MachineLearningPipeline/parameter")

os.getcwd()

"""### `Load Data`

`Data Parameter Lingkungan` : Parameters.tif

`Data Kejadian Longsor` : Titik_Training.shp
"""

# Membuat variabel dari data yang dipanggil
parametertif = 'Parameters.tif' # Predictor
training_file = 'Titik_Training.shp' # Target

# Membuat objek stack yang mewakili data raster
stack = Raster(parametertif)
stack.names

# Cek sistem koordinat/proyeksi
crstif = stack.crs
print("CRS dari data raster:", crstif)

stack.names = ('aspect', 'elevation', 'landuse', 'litologi', 'ndbi', 'ndvi', 'rain',  'river', 'road',  'slope',  'structure',  'soil')

# Baca file shapefile sebagai GeoDataFrame
gdf = gpd.read_file(training_file)

# Mengubah sistem koordinat menjadi EPSG:4326 agar sama dengan data raster
gdf = gdf.to_crs(epsg=4326)
gdf['Class'] = gdf['Class'].astype(float)

# Simpan kembali sebagai shapefile
gdf.to_file('titik_output.shp')

# Panggil kembali
training_pts_file = 'titik_output.shp'

# Plot prediktor (Layer raster)
mpl.style.use('seaborn-ticks')
axs = stack.plot(figsize=(9, 7))
ax = axs.flatten()[10]
im = ax.images
im[0].colorbar.set_ticks([1,2,3])
ax = axs.flatten()[8]
ax.tick_params(axis='x', labelrotation=65)

plt.tight_layout()
plt.show()

"""### `Spatial Information`"""

# Membuat grid koordinat
xy_layer = xy_coordinates(
    layer=stack.iloc[0],
    file_path=NamedTemporaryFile(suffix=".tif").name
)

edms = distance_to_corners(
    layer=stack.iloc[0],
    file_path=NamedTemporaryFile(suffix=".tif").name
)
edms.rename(
    {old: new for (old, new) in zip(edms.names, ["tl", "tr", "bl", "br", "c"])},
    in_place=True
)

edms.plot()
plt.show()

# Menambahkanya dengan objek stack
stack = stack.append([xy_layer, edms])

# Plot prediktor baru
mpl.style.use('seaborn-ticks')
axs = stack.plot(figsize=(9, 7))
ax = axs.flatten()[10]
im = ax.images
im[0].colorbar.set_ticks([1,2,3])
ax = axs.flatten()[8]
ax.tick_params(axis='x', labelrotation=65)

plt.tight_layout()
plt.show()

# Melakukan intersect dengan object stack
stack = stack.intersect()

# Hasil plot prediktor
mpl.style.use('seaborn-ticks')
axs = stack.plot(figsize=(9, 7))
ax = axs.flatten()[10]
im = ax.images
im[0].colorbar.set_ticks([1,2,3])
ax = axs.flatten()[8]
ax.tick_params(axis='x', labelrotation=65)

plt.tight_layout()
plt.show()

stack

"""##**3. PREPROCESSING DATA**

###`Data SHP`
"""

# Membaca data
training_pts = gpd.read_file(training_pts_file)
training_pts.head()

print(training_pts.dtypes)

# Cek proyeksi kembali
crs = training_pts.crs
print("CRS dari data shapefile:", crs)

# Plotting data training
from mpl_toolkits.axes_grid1 import make_axes_locatable
mpl.style.use('ggplot')

fig, axs = plt.subplots(2, figsize=(8.5, 7))

for i, (ax, target) in enumerate(zip(axs.ravel(), ['Class'])):
    ax.set_title(target.title())
    divider = make_axes_locatable(ax)
    cax = divider.append_axes("right", size="10%", pad=0.05)
    training_pts.plot(column=target, legend=True, ax=ax, cax=cax, cmap='viridis')

    if i != 0:
        ax.set_yticklabels([])

    if i != 3:
        ax.set_xticklabels([])
    else:
        ax.tick_params(axis='x', labelrotation=65)

fig.delaxes(axs.flatten()[i+1])
plt.tight_layout()
plt.show()

"""### `Data Raster`"""

# Ekstrak raster untuk nilai parameter
training_df = stack.extract_vector(gdf=training_pts)

training_df.index = training_df.index.get_level_values("geometry_idx")
training_df = training_df.merge(
    training_pts.loc[:, ("Class")],
    left_index=True,
    right_index=True
)

# Cleaning missing values
training_df = training_df.dropna()
training_df.head()

# Mengetahui jumlah baris dan nama kolom
print("Jumlah baris dalam data:", stack.shape[0])
print(training_df.columns)

"""## **4. MODEL  PREDIKSI DENGAN MACHINE LEARNING**

###`ML Pipeline`
"""

stack.names

# Membuat Machine Learning
longsor_idx = [i for i, name in enumerate(stack.names) if name == 'Class']

trans = ColumnTransformer([
    ('ohe', OneHotEncoder(categories='auto', handle_unknown='ignore'), longsor_idx)
    ], remainder='passthrough')
# Model Selection : Random
rf = RandomForestRegressor(n_estimators=500, n_jobs=-1, random_state=1234)
rf = Pipeline([
    ('preproc', trans),
    ('regressor', rf)])

# Memisahkan variabel response/target (y: dependent) dengan variabel prediktor (x: independent)
X = training_df.loc[:, stack.names]
y = training_df.loc[:, ['Class']]
rf.fit(X, y)

"""###`Validation - Evaluasi Model`"""

# Cross-validation untuk evaluasi model
outer = KFold(n_splits=10, shuffle=True, random_state=1234)
scores = cross_validate(rf, X, y, scoring='neg_mean_squared_error', cv=10, n_jobs=1)
rmse = np.sqrt(-scores['test_score']).mean()

print("Our RMSE score is {}".format(rmse))

"""##**5. ANALISIS DAN INTERPRETASI HASIL**

###`Feature Importances`
"""

ohe_names = deepcopy(list(stack.names))
if longsor_idx:
    ohe_names.insert(longsor_idx[0], 'Class1')
ohe_names = np.array(ohe_names)

mpl.style.use('ggplot')

fimp = rf.named_steps['regressor'].feature_importances_

fig, ax = plt.subplots(figsize=(4, 6))
ax.barh(y=ohe_names[fimp.argsort()], width=fimp[fimp.argsort()])
ax.set_xlabel('Feature Importance Score')
plt.show()

"""###`Visualisasi`"""

preds = stack.predict(rf)
preds.rename(
    {old: new for old, new in zip(preds.names, ['Prediksi_Longsor'])},
    in_place=True
)
preds.Prediksi_Longsor.cmap = 'rainbow'

mpl.style.use('seaborn-ticks')
preds.plot(out_shape=(200, 200), title_fontsize=14, figsize=(10, 8))
plt.show()